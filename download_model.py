#!/usr/bin/env python3
"""
Anime-Whisper Model Downloader
Downloads the anime-whisper model for offline use in VoiceTransl
"""

import os
import sys
import torch
from transformers import pipeline
import logging
from pathlib import Path

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_system_requirements():
    """Check if system meets minimum requirements"""
    logger.info("æ£€æŸ¥ç³»ç»Ÿè¦æ±‚...")
    
    # Check Python version
    python_version = sys.version_info
    if python_version < (3, 8):
        logger.error(f"Python ç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        logger.error("éœ€è¦ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    
    logger.info(f"âœ… Python ç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # Check PyTorch
    try:
        logger.info(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        
        # Check device availability
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            logger.info(f"âœ… CUDA å¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {device_count}")
            for i in range(device_count):
                logger.info(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            logger.info("âœ… MPS (Apple Silicon) å¯ç”¨")
        else:
            logger.info("â„¹ï¸  å°†ä½¿ç”¨ CPU æ¨¡å¼")
            
    except ImportError:
        logger.error("âŒ PyTorch æœªå®‰è£…")
        logger.error("è¯·è¿è¡Œ: pip install torch torchaudio")
        return False
    
    # Check transformers
    try:
        import transformers
        logger.info(f"âœ… Transformers ç‰ˆæœ¬: {transformers.__version__}")
    except ImportError:
        logger.error("âŒ Transformers æœªå®‰è£…")
        logger.error("è¯·è¿è¡Œ: pip install transformers>=4.21.0")
        return False
    
    return True

def get_cache_directory():
    """Get the Hugging Face cache directory"""
    cache_dir = os.environ.get('HF_HOME', 
                              os.path.join(os.path.expanduser('~'), '.cache', 'huggingface'))
    model_cache = os.path.join(cache_dir, 'hub', 'models--litagin--anime-whisper')
    return Path(model_cache)

def download_model():
    """Download the anime-whisper model"""
    logger.info("å¼€å§‹ä¸‹è½½ anime-whisper æ¨¡å‹...")
    logger.info("æ¨¡å‹å¤§å°çº¦ 756MBï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    try:
        # Create pipeline to trigger model download
        pipe = pipeline(
            "automatic-speech-recognition",
            model="litagin/anime-whisper",
            device="cpu",  # Use CPU for download to avoid GPU memory issues
            torch_dtype=torch.float32,
        )
        
        logger.info("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        
        # Get model info
        model_info = {
            "model_name": pipe.model.config._name_or_path,
            "model_type": pipe.model.config.model_type,
            "vocab_size": getattr(pipe.model.config, 'vocab_size', 'Unknown'),
        }
        
        logger.info("æ¨¡å‹ä¿¡æ¯:")
        for key, value in model_info.items():
            logger.info(f"  {key}: {value}")
        
        # Show cache location
        cache_dir = get_cache_directory()
        if cache_dir.exists():
            logger.info(f"æ¨¡å‹ç¼“å­˜ä½ç½®: {cache_dir}")
            
            # Calculate cache size
            total_size = sum(f.stat().st_size for f in cache_dir.rglob('*') if f.is_file())
            size_mb = total_size / (1024 * 1024)
            logger.info(f"ç¼“å­˜å¤§å°: {size_mb:.1f} MB")
        
        # Clean up pipeline
        del pipe
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        logger.error("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•ä½¿ç”¨ä»£ç†")
        return False

def test_model():
    """Test the downloaded model"""
    logger.info("æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        from anime_whisper_backend import AnimeWhisperBackend
        
        backend = AnimeWhisperBackend()
        if backend.initialize():
            logger.info("âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
            
            info = backend.get_backend_info()
            logger.info("åç«¯ä¿¡æ¯:")
            for key, value in info.items():
                if key != 'features':
                    logger.info(f"  {key}: {value}")
            
            backend.cleanup()
            return True
        else:
            logger.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            return False
            
    except ImportError:
        logger.warning("âš ï¸  anime_whisper_backend.py æœªæ‰¾åˆ°ï¼Œè·³è¿‡åç«¯æµ‹è¯•")
        logger.info("è¯·ç¡®ä¿ anime_whisper_backend.py åœ¨é¡¹ç›®ç›®å½•ä¸­")
        return True
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def setup_offline_mode():
    """Setup environment for offline mode"""
    logger.info("é…ç½®ç¦»çº¿æ¨¡å¼...")
    
    # Set environment variables for offline mode
    os.environ["TRANSFORMERS_OFFLINE"] = "1"
    os.environ["HF_DATASETS_OFFLINE"] = "1"
    
    logger.info("âœ… ç¦»çº¿æ¨¡å¼å·²é…ç½®")
    logger.info("ç¯å¢ƒå˜é‡å·²è®¾ç½®:")
    logger.info("  TRANSFORMERS_OFFLINE=1")
    logger.info("  HF_DATASETS_OFFLINE=1")

def main():
    """Main function"""
    print("=" * 60)
    print("ğŸŒ Anime-Whisper æ¨¡å‹ä¸‹è½½å™¨")
    print("=" * 60)
    
    # Check system requirements
    if not check_system_requirements():
        logger.error("ç³»ç»Ÿè¦æ±‚æ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…å¿…è¦çš„ä¾èµ–")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    
    # Download model
    if not download_model():
        logger.error("æ¨¡å‹ä¸‹è½½å¤±è´¥")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    
    # Test model
    if not test_model():
        logger.warning("æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œä½†ä¸‹è½½å¯èƒ½å·²å®Œæˆ")
    
    print("\n" + "=" * 60)
    
    # Setup offline mode
    setup_offline_mode()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å®‰è£…å®Œæˆï¼")
    print("=" * 60)
    print("\nä½¿ç”¨è¯´æ˜:")
    print("1. åœ¨ VoiceTransl ä¸­é€‰æ‹© 'anime-whisper' æ¨¡å‹")
    print("2. é€‰æ‹©æ—¥è¯­éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè½¬å½•")
    print("3. äº«å—é«˜è´¨é‡çš„åŠ¨ç”»è¯­éŸ³è¯†åˆ«ï¼")
    print("\næ³¨æ„äº‹é¡¹:")
    print("- æ¨¡å‹ä¸“é—¨é’ˆå¯¹æ—¥è¯­åŠ¨ç”»/æ¸¸æˆè¯­éŸ³ä¼˜åŒ–")
    print("- æ”¯æŒéè¯­è¨€éŸ³æ•ˆè¯†åˆ«ï¼ˆç¬‘å£°ã€å¹æ¯ç­‰ï¼‰")
    print("- å¦‚é‡åˆ°é‡å¤å¹»è§‰ï¼Œå¯å¯ç”¨é‡å¤æŠ‘åˆ¶é€‰é¡¹")
    print("\nå¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ ANIME_WHISPER_SETUP.md æ–‡æ¡£")

if __name__ == "__main__":
    main()
