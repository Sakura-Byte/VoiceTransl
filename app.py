import sys, os

# if _MEIPASS is in sys
if '_MEIPASS' in sys.__dict__:
    os.chdir(sys._MEIPASS)
    
import shutil
from PyQt6 import QtGui, QtCore
from PyQt6.QtCore import Qt, QThread, QObject, pyqtSignal, QTimer, QDateTime, QSize
from PyQt6.QtWidgets import QApplication, QVBoxLayout, QFileDialog, QFrame
from qfluentwidgets import PushButton as QPushButton, TextEdit as QTextEdit, LineEdit as QLineEdit, ComboBox as QComboBox, Slider as QSlider, FluentWindow as QMainWindow, PlainTextEdit as QPlainTextEdit, SplashScreen
from qfluentwidgets import FluentIcon, NavigationItemPosition, SubtitleLabel, TitleLabel, BodyLabel

import re
import json
import requests
import subprocess
from time import sleep
from prompt2srt import make_srt, make_lrc
from srt2prompt import make_prompt
from GalTransl.__main__ import worker

ONLINE_TRANSLATOR_MAPPING = {
    'moonshot': 'https://api.moonshot.cn',
    'glm': 'https://open.bigmodel.cn/api/paas',
    'deepseek': 'https://api.deepseek.com',
    'minimax': 'https://api.minimax.chat',
    'doubao': 'https://ark.cn-beijing.volces.com/api',
    'aliyun': 'https://dashscope.aliyuncs.com/compatible-mode',
    'gemini': 'https://generativelanguage.googleapis.com',
    'ollama': 'http://localhost:11434',
    'llamacpp': 'http://localhost:8989',
}

TRANSLATOR_SUPPORTED = [
    'ä¸è¿›è¡Œç¿»è¯‘',
    "gpt-custom",
    "sakura-009",
    "sakura-010",
    "galtransl"
] + list(ONLINE_TRANSLATOR_MAPPING.keys())

# redirect sys.stdout and sys.stderr to one log file
LOG_PATH = 'log.txt'
sys.stdout = open(LOG_PATH, 'w', encoding='utf-8')
sys.stderr = sys.stdout

class Widget(QFrame):

    def __init__(self, text: str, parent=None):
        super().__init__(parent=parent)
        # Set the scroll area as the parent of the widget
        self.vBoxLayout = QVBoxLayout(self)

        # Must set a globally unique object name for the sub-interface
        self.setObjectName(text.replace(' ', '-'))

class MainWindow(QMainWindow):
    status = pyqtSignal(str)

    def __init__(self):
        super().__init__()
        self.thread = None
        self.worker = None
        self.setWindowTitle("VoiceTransl")
        self.setWindowIcon(QtGui.QIcon('icon.png'))
        self.status.connect(lambda x: self.setWindowTitle(f"VoiceTransl - {x}"))
        self.resize(800, 600)
        self.splashScreen = SplashScreen(self.windowIcon(), self)
        self.splashScreen.setIconSize(QSize(102, 102))
        self.show()
        self.initUI()
        self.setup_timer()
        self.splashScreen.finish()
        
    def initUI(self):
        self.initAboutTab()
        self.initInputOutputTab()
        self.initLogTab()
        self.initSettingsTab()
        self.initAdvancedSettingTab()
        self.initDictTab()

        # load config (simplified - no whisper model selection needed)
        if os.path.exists('config.txt'):
            with open('config.txt', 'r', encoding='utf-8') as f:
                lines = f.readlines()
                if len(lines) >= 8:  # Skip whisper_file (line 0), start from translator
                    translator = lines[1].strip()
                    language = lines[2].strip()
                    gpt_token = lines[3].strip()
                    gpt_address = lines[4].strip()
                    gpt_model = lines[5].strip()
                    sakura_file = lines[6].strip()
                    sakura_mode = int(lines[7].strip())
                    output_format = lines[8].strip()

                    self.translator_group.setCurrentText(translator)
                    self.input_lang.setCurrentText(language)
                    self.gpt_token.setText(gpt_token)
                    self.gpt_address.setText(gpt_address)
                    self.gpt_model.setText(gpt_model)
                    if self.sakura_file: self.sakura_file.setCurrentText(sakura_file)
                    self.sakura_mode.setValue(sakura_mode)

                    self.output_format.setCurrentText(output_format)

        # Load anime-whisper config if exists
        if os.path.exists('anime_whisper_config.txt'):
            with open('anime_whisper_config.txt', 'r', encoding='utf-8') as f:
                config_line = f.read().strip()
                if config_line == 'suppress_repetitions':
                    self.suppress_repetitions.setCurrentText('å¯ç”¨é‡å¤æŠ‘åˆ¶')

        if os.path.exists('llama/param.txt'):
            with open('llama/param.txt', 'r', encoding='utf-8') as f:
                self.param_llama.setPlainText(f.read())

        if os.path.exists('project/dict_pre.txt'):
            with open('project/dict_pre.txt', 'r', encoding='utf-8') as f:
                self.before_dict.setPlainText(f.read())

        if os.path.exists('project/dict_gpt.txt'):
            with open('project/dict_gpt.txt', 'r', encoding='utf-8') as f:
                self.gpt_dict.setPlainText(f.read())

        if os.path.exists('project/dict_after.txt'):
            with open('project/dict_after.txt', 'r', encoding='utf-8') as f:
                self.after_dict.setPlainText(f.read())

        if os.path.exists('project/extra_prompt.txt'):
            with open('project/extra_prompt.txt', 'r', encoding='utf-8') as f:
                self.extra_prompt.setPlainText(f.read())

    def setup_timer(self):
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.read_log_file)
        self.timer.start(1000)
        self.last_read_position = 0
        self.file_not_found_message_shown = False

    def read_log_file(self):
        """è¯»å–æ—¥å¿—æ–‡ä»¶å¹¶æ›´æ–°æ˜¾ç¤º"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(LOG_PATH):
                if not self.file_not_found_message_shown:
                    timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                    self.log_display.setPlainText(f"[{timestamp}] é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{LOG_PATH}' æœªæ‰¾åˆ°ã€‚æ­£åœ¨ç­‰å¾…æ–‡ä»¶åˆ›å»º...\n")
                    self.file_not_found_message_shown = True
                self.last_read_position = 0 # å¦‚æœæ–‡ä»¶æ¶ˆå¤±äº†ï¼Œé‡ç½®è¯»å–ä½ç½®
                return

            # å¦‚æœæ–‡ä»¶ä¹‹å‰æœªæ‰¾åˆ°ä½†ç°åœ¨æ‰¾åˆ°äº†
            if self.file_not_found_message_shown:
                self.log_display.clear() # æ¸…é™¤ä¹‹å‰çš„é”™è¯¯ä¿¡æ¯
                self.file_not_found_message_shown = False
                self.last_read_position = 0 # ä»å¤´å¼€å§‹è¯»

            with open(LOG_PATH, 'r', encoding='utf-8', errors='replace') as f:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«æˆªæ–­æˆ–æ›¿æ¢ (ä¾‹å¦‚æ—¥å¿—è½®è½¬)
                # é€šè¿‡ seek(0, 2) è·å–å½“å‰æ–‡ä»¶å¤§å°
                current_file_size = f.seek(0, os.SEEK_END)
                if current_file_size < self.last_read_position:
                    # æ–‡ä»¶å˜å°äº†ï¼Œæ„å‘³ç€æ–‡ä»¶è¢«æˆªæ–­æˆ–æ›¿æ¢äº†
                    timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                    self.log_display.appendPlainText(f"\n[{timestamp}] æ£€æµ‹åˆ°æ—¥å¿—æ–‡ä»¶æˆªæ–­æˆ–è½®è½¬ã€‚ä»å¤´å¼€å§‹è¯»å–...\n")
                    self.last_read_position = 0
                    # å¯ä»¥é€‰æ‹©æ¸…ç©ºæ˜¾ç¤º: self.log_display.clear()
                    # ä½†é€šå¸¸è¿½åŠ æç¤ºç„¶åä»å¤´è¯»æ–°å†…å®¹æ›´å¥½

                f.seek(self.last_read_position)
                new_content = f.read()
                if new_content:
                    self.log_display.appendPlainText(new_content) # appendPlainText ä¼šè‡ªåŠ¨å¤„ç†æ¢è¡Œ
                    # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
                    scrollbar = self.log_display.verticalScrollBar()
                    scrollbar.setValue(scrollbar.maximum())

                self.last_read_position = f.tell() # æ›´æ–°ä¸‹æ¬¡è¯»å–çš„èµ·å§‹ä½ç½®

        except FileNotFoundError: # è¿™ä¸ªç†è®ºä¸Šåœ¨ä¸Šé¢çš„ os.path.exists æ£€æŸ¥åä¸åº”é¢‘ç¹è§¦å‘
            if not self.file_not_found_message_shown:
                timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
                self.log_display.setPlainText(f"[{timestamp}] é”™è¯¯: æ—¥å¿—æ–‡ä»¶ '{LOG_PATH}' å†æ¬¡æ£€æŸ¥æ—¶æœªæ‰¾åˆ°ã€‚\n")
                self.file_not_found_message_shown = True
            self.last_read_position = 0
        except IOError as e:
            timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
            self.log_display.appendPlainText(f"[{timestamp}] è¯»å–æ—¥å¿—æ–‡ä»¶IOé”™è¯¯: {e}\n")
            # å¯ä»¥è€ƒè™‘åœ¨IOé”™è¯¯æ—¶åœæ­¢timeræˆ–åšå…¶ä»–å¤„ç†
        except Exception as e:
            timestamp = QDateTime.currentDateTime().toString("yyyy-MM-dd hh:mm:ss")
            self.log_display.appendPlainText(f"[{timestamp}] è¯»å–æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\n")

    def closeEvent(self, event):
        """ç¡®ä¿åœ¨å…³é—­çª—å£æ—¶åœæ­¢å®šæ—¶å™¨"""
        self.timer.stop()
        event.accept()

    def initLogTab(self):
        self.log_tab = Widget("Log", self)
        self.log_layout = self.log_tab.vBoxLayout
        self.log_layout.addWidget(BodyLabel("ğŸ“œ æ—¥å¿—æ–‡ä»¶"))

        # log
        self.log_display = QPlainTextEdit(self)
        self.log_display.setReadOnly(True)
        self.log_display.setStyleSheet("font-family: Consolas, Monospace; font-size: 10pt;") # è®¾ç½®ç­‰å®½å­—ä½“
        self.log_layout.addWidget(self.log_display)

        self.addSubInterface(self.log_tab, FluentIcon.INFO, "æ—¥å¿—", NavigationItemPosition.TOP)

    def initAboutTab(self):
        self.about_tab = Widget("About", self)
        self.about_layout = self.about_tab.vBoxLayout

        # introduce
        self.about_layout.addWidget(TitleLabel("ğŸ‰ æ„Ÿè°¢ä½¿ç”¨VoiceTranslï¼"))
        self.introduce_text = QTextEdit()
        self.introduce_text.setReadOnly(True)
        self.introduce_text.setPlainText(
"""
VoiceTranslï¼ˆåŸGaltransl for ASMRï¼‰æ˜¯ä¸€ä¸ªå¼€æºå…è´¹çš„ç¦»çº¿AIè§†é¢‘å­—å¹•ç”Ÿæˆå’Œç¿»è¯‘è½¯ä»¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æœ¬ç¨‹åºä»å¤–è¯­éŸ³è§†é¢‘æ–‡ä»¶/å­—å¹•æ–‡ä»¶ç”Ÿæˆä¸­æ–‡å­—å¹•æ–‡ä»¶ã€‚

é¡¹ç›®åœ°å€åŠä½¿ç”¨è¯´æ˜: https://github.com/shinnpuru/VoiceTranslã€‚
Bç«™æ•™ç¨‹ï¼šhttps://space.bilibili.com/36464441/lists/3239068ã€‚
""")
        self.about_layout.addWidget(self.introduce_text)

        # mode
        self.about_layout.addWidget(TitleLabel("ğŸ”§ æ¨¡å¼è¯´æ˜"))
        self.mode_text = QTextEdit()
        self.mode_text.setReadOnly(True)
        self.mode_text.setPlainText(
"""
ï¼ˆ1ï¼‰ä»…ä¸‹è½½æ¨¡å¼ï¼šé€‰æ‹©ä¸è¿›è¡Œå¬å†™å’Œä¸è¿›è¡Œç¿»è¯‘ï¼›
ï¼ˆ2ï¼‰ä»…å¬å†™æ¨¡å¼ï¼šé€‰æ‹©å¬å†™æ¨¡å‹ï¼Œé€‰æ‹©ä¸è¿›è¡Œç¿»è¯‘ï¼›
ï¼ˆ3ï¼‰ä»…ç¿»è¯‘æ¨¡å¼ï¼šä¸Šä¼ SRTæ–‡ä»¶ï¼Œå¹¶ä¸”é€‰æ‹©ç¿»è¯‘æ¨¡å‹ï¼›  
ï¼ˆ4ï¼‰å®Œæ•´æ¨¡å¼ï¼šé€‰æ‹©æ‰€æœ‰åŠŸèƒ½ã€‚
""")
        self.about_layout.addWidget(self.mode_text)

        # disclaimer
        self.about_layout.addWidget(TitleLabel("ğŸ‡ æ”¯æŒæ˜•è’²"))
        self.disclaimer_text = QTextEdit()
        self.disclaimer_text.setReadOnly(True)
        self.disclaimer_text.setPlainText(
"""
å¦‚æœæ‚¨å–œæ¬¢è¿™ä¸ªé¡¹ç›®å¹¶å¸Œæœ›æ”¯æŒå¼€å‘ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼èµåŠ©ï¼š
1. çˆ±å‘ç”µ: https://afdian.com/a/shinnpuruï¼ˆå¾®ä¿¡å’Œæ”¯ä»˜å®ï¼‰
2. Bç«™å……ç”µ: https://space.bilibili.com/36464441ï¼ˆå¤§ä¼šå‘˜å¯ç”¨å…è´¹Bå¸ï¼‰
3. Ko-fi: https://ko-fi.com/U7U018MISYï¼ˆPayPalåŠä¿¡ç”¨å¡ï¼‰
æ‚¨çš„æ”¯æŒå°†å¸®åŠ©æ˜•è’²æŒç»­æ”¹è¿›å’Œç»´æŠ¤è¿™ä¸ªé¡¹ç›®ï¼
""")
        self.about_layout.addWidget(self.disclaimer_text)

        # start
        self.start_button = QPushButton("ğŸš€ å¼€å§‹")
        self.start_button.clicked.connect(lambda: self.switchTo(self.input_output_tab))
        self.about_layout.addWidget(self.start_button)

        self.addSubInterface(self.about_tab, FluentIcon.HEART, "å…³äº", NavigationItemPosition.TOP)
        
    def initInputOutputTab(self):
        self.input_output_tab = Widget("Home", self)
        self.input_output_layout = self.input_output_tab.vBoxLayout
        
        # Input Section
        self.input_output_layout.addWidget(BodyLabel("ğŸ“‚ è¯·æ‹–æ‹½éŸ³è§†é¢‘æ–‡ä»¶/SRTæ–‡ä»¶åˆ°è¿™é‡Œï¼Œå¯å¤šé€‰ï¼Œè·¯å¾„è¯·å‹¿åŒ…å«éè‹±æ–‡å’Œç©ºæ ¼ã€‚"))
        self.input_files_list = QTextEdit()
        self.input_files_list.setAcceptDrops(True)
        self.input_files_list.dropEvent = lambda e: self.input_files_list.setPlainText('\n'.join([i[8:] for i in e.mimeData().text().split('\n')]))
        self.input_files_list.setPlaceholderText("å½“å‰æœªé€‰æ‹©æœ¬åœ°æ–‡ä»¶...")
        self.input_output_layout.addWidget(self.input_files_list)



        # Format Section
        self.input_output_layout.addWidget(BodyLabel("ğŸ¥ é€‰æ‹©è¾“å‡ºçš„å­—å¹•æ ¼å¼ã€‚"))
        self.output_format = QComboBox()
        self.output_format.addItems(['åŸæ–‡SRT', 'ä¸­æ–‡LRC', 'ä¸­æ–‡SRT'])
        self.output_format.setCurrentText('ä¸­æ–‡SRT')
        self.input_output_layout.addWidget(self.output_format)

        self.run_button = QPushButton("ğŸš€ è¿è¡Œ")
        self.run_button.clicked.connect(self.run_worker)
        self.input_output_layout.addWidget(self.run_button)

        self.output_text_edit = QTextEdit()
        self.output_text_edit.setReadOnly(True)
        self.output_text_edit.setPlaceholderText("å½“å‰æ— è¾“å‡ºä¿¡æ¯...")
        self.status.connect(self.output_text_edit.append)
        self.input_output_layout.addWidget(self.output_text_edit)

        self.open_output_button = QPushButton("ğŸ“ æ‰“å¼€ä¸‹è½½å’Œç¼“å­˜æ–‡ä»¶å¤¹")
        self.open_output_button.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'project/cache')))
        self.input_output_layout.addWidget(self.open_output_button)
        
        self.clean_button = QPushButton("ğŸ§¹ æ¸…ç©ºä¸‹è½½å’Œç¼“å­˜")
        self.clean_button.clicked.connect(self.cleaner)
        self.input_output_layout.addWidget(self.clean_button)
        
        self.addSubInterface(self.input_output_tab, FluentIcon.HOME, "ä¸»é¡µ", NavigationItemPosition.TOP)

    def initDictTab(self):
        self.dict_tab = Widget("Dict", self)
        self.dict_layout = self.dict_tab.vBoxLayout

        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘å‰çš„å­—å…¸ã€‚"))
        self.before_dict = QTextEdit()
        self.before_dict.setPlaceholderText("æ—¥æ–‡åŸæ–‡(Tabé”®)æ—¥æ–‡æ›¿æ¢è¯\næ—¥æ–‡åŸæ–‡(Tabé”®)æ—¥æ–‡æ›¿æ¢è¯")
        self.dict_layout.addWidget(self.before_dict)
        
        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘ä¸­çš„å­—å…¸ã€‚"))
        self.gpt_dict = QTextEdit()
        self.gpt_dict.setPlaceholderText("æ—¥æ–‡(Tabé”®)ä¸­æ–‡\næ—¥æ–‡(Tabé”®)ä¸­æ–‡")
        self.dict_layout.addWidget(self.gpt_dict)
        
        self.dict_layout.addWidget(BodyLabel("ğŸ“š é…ç½®ç¿»è¯‘åçš„å­—å…¸ã€‚"))
        self.after_dict = QTextEdit()
        self.after_dict.setPlaceholderText("ä¸­æ–‡åŸæ–‡(Tabé”®)ä¸­æ–‡æ›¿æ¢è¯\nä¸­æ–‡åŸæ–‡(Tabé”®)ä¸­æ–‡æ›¿æ¢è¯")
        self.dict_layout.addWidget(self.after_dict)

        self.dict_layout.addWidget(BodyLabel("ğŸ“• é…ç½®é¢å¤–æç¤ºã€‚"))
        self.extra_prompt = QTextEdit()
        self.extra_prompt.setPlaceholderText("è¯·åœ¨è¿™é‡Œè¾“å…¥é¢å¤–çš„æç¤ºä¿¡æ¯ï¼Œä¾‹å¦‚ä¸–ç•Œä¹¦æˆ–å°æœ¬å†…å®¹ã€‚")
        self.dict_layout.addWidget(self.extra_prompt)

        self.addSubInterface(self.dict_tab, FluentIcon.DICTIONARY, "å­—å…¸è®¾ç½®", NavigationItemPosition.TOP)
        
    def initSettingsTab(self):
        self.settings_tab = Widget("Settings", self)
        self.settings_layout = self.settings_tab.vBoxLayout
        
        # Hybrid transcription system with improved timestamp accuracy
        self.settings_layout.addWidget(BodyLabel("ğŸš€ æ··åˆè½¬å½•ç³»ç»Ÿ: TinyWhisper(æ—¶é—´æˆ³) + AnimeWhisper(æ–‡æœ¬) + æ™ºèƒ½å¯¹é½"))

        self.settings_layout.addWidget(BodyLabel("ğŸŒ é€‰æ‹©è¾“å…¥çš„è¯­è¨€ã€‚(ja=æ—¥è¯­ï¼Œen=è‹±è¯­ï¼Œko=éŸ©è¯­ï¼Œru=ä¿„è¯­ï¼Œfr=æ³•è¯­ï¼Œzh=ä¸­æ–‡ï¼Œä»…å¬å†™ï¼‰"))
        self.input_lang = QComboBox()
        self.input_lang.addItems(['ja','en','ko','ru','fr','zh'])
        self.settings_layout.addWidget(self.input_lang)

        self.settings_layout.addWidget(BodyLabel("ğŸ”§ è½¬å½•ç³»ç»Ÿé…ç½®é€‰é¡¹"))

        # Alignment backend selection
        self.alignment_backend = QComboBox()
        self.alignment_backend.addItems(['æœ¬åœ°Qwen3æ¨¡å‹', 'OpenAIå…¼å®¹API', 'GeminiåŸç”ŸAPI'])
        self.alignment_backend.setCurrentText('æœ¬åœ°Qwen3æ¨¡å‹')
        self.settings_layout.addWidget(BodyLabel("å¯¹é½åç«¯:"))
        self.settings_layout.addWidget(self.alignment_backend)

        # API configuration (initially hidden)
        self.api_config_label = BodyLabel("ğŸŒ APIé…ç½®:")
        self.settings_layout.addWidget(self.api_config_label)

        # API endpoint (for OpenAI-compatible APIs)
        self.api_endpoint = QLineEdit()
        self.api_endpoint.setPlaceholderText("APIç«¯ç‚¹ (ä¾‹å¦‚: https://api.openai.com/v1)")
        self.api_endpoint.setText("https://api.openai.com/v1")
        self.api_endpoint_label = BodyLabel("APIç«¯ç‚¹:")
        self.settings_layout.addWidget(self.api_endpoint_label)
        self.settings_layout.addWidget(self.api_endpoint)

        # API key (for all API backends)
        self.api_key = QLineEdit()
        self.api_key.setPlaceholderText("APIå¯†é’¥")
        self.api_key.setEchoMode(QLineEdit.EchoMode.Password)
        self.api_key_label = BodyLabel("APIå¯†é’¥:")
        self.settings_layout.addWidget(self.api_key_label)
        self.settings_layout.addWidget(self.api_key)

        # Model selection (different for different backends)
        self.api_model_label = BodyLabel("æ¨¡å‹:")
        self.settings_layout.addWidget(self.api_model_label)

        # OpenAI/Generic model input
        self.api_model_input = QLineEdit()
        self.api_model_input.setPlaceholderText("æ¨¡å‹åç§° (ä¾‹å¦‚: gpt-4, gpt-3.5-turbo)")
        self.api_model_input.setText("gpt-4")
        self.settings_layout.addWidget(self.api_model_input)

        # Gemini model selection
        self.gemini_model_combo = QComboBox()
        self.gemini_model_combo.addItems([
            'gemini-2.5-pro',
            'gemini-2.5-flash',
            'gemini-2.5-flash-lite'
        ])
        self.gemini_model_combo.setCurrentText('gemini-2.0-flash-exp')
        self.settings_layout.addWidget(self.gemini_model_combo)

        # Initially hide API config
        self._toggle_api_config(False, "openai")

        # Connect alignment backend change to toggle API config
        self.alignment_backend.currentTextChanged.connect(self._on_alignment_backend_changed)

        # Repetition handling option
        self.suppress_repetitions = QComboBox()
        self.suppress_repetitions.addItems(['å…³é—­é‡å¤æŠ‘åˆ¶', 'å¯ç”¨é‡å¤æŠ‘åˆ¶'])
        self.suppress_repetitions.setCurrentText('å…³é—­é‡å¤æŠ‘åˆ¶')
        self.settings_layout.addWidget(BodyLabel("é‡å¤æŠ‘åˆ¶ï¼ˆå¦‚æœå‡ºç°é‡å¤å¹»è§‰å¯å¯ç”¨ï¼‰ï¼š"))
        self.settings_layout.addWidget(self.suppress_repetitions)

        self.addSubInterface(self.settings_tab, FluentIcon.MUSIC, "å¬å†™è®¾ç½®", NavigationItemPosition.TOP)

    def _toggle_api_config(self, show: bool, backend_type: str = "openai"):
        """Toggle visibility of API configuration fields"""
        self.api_config_label.setVisible(show)
        self.api_key.setVisible(show)
        self.api_key_label.setVisible(show)
        self.api_model_label.setVisible(show)

        # Show/hide endpoint based on backend type
        is_openai = (backend_type == "openai")
        self.api_endpoint.setVisible(show and is_openai)
        self.api_endpoint_label.setVisible(show and is_openai)

        # Show appropriate model selection widget
        self.api_model_input.setVisible(show and is_openai)
        self.gemini_model_combo.setVisible(show and not is_openai)

    def _on_alignment_backend_changed(self, text: str):
        """Handle alignment backend selection change"""
        show_api_config = (text in ['OpenAIå…¼å®¹API', 'GeminiåŸç”ŸAPI'])

        if text == 'GeminiåŸç”ŸAPI':
            self._toggle_api_config(show_api_config, "gemini")
            # Set default Gemini model
            self.gemini_model_combo.setCurrentText("gemini-2.0-flash-exp")
        elif text == 'OpenAIå…¼å®¹API':
            self._toggle_api_config(show_api_config, "openai")
            # Set default OpenAI values
            self.api_endpoint.setText("https://api.openai.com/v1")
            self.api_model_input.setText("gpt-4")
        else:
            self._toggle_api_config(False, "openai")

    def initAdvancedSettingTab(self):
        self.advanced_settings_tab = Widget("AdvancedSettings", self)
        self.advanced_settings_layout = self.advanced_settings_tab.vBoxLayout

        # Translator Section
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ é€‰æ‹©ç”¨äºç¿»è¯‘çš„æ¨¡å‹ç±»åˆ«ã€‚"))
        self.translator_group = QComboBox()
        self.translator_group.addItems(TRANSLATOR_SUPPORTED)
        self.advanced_settings_layout.addWidget(self.translator_group)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ åœ¨çº¿æ¨¡å‹ä»¤ç‰Œ"))
        self.gpt_token = QLineEdit()
        self.gpt_token.setPlaceholderText("ç•™ç©ºä¸ºä½¿ç”¨ä¸Šæ¬¡é…ç½®çš„Tokenã€‚")
        self.advanced_settings_layout.addWidget(self.gpt_token)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ åœ¨çº¿æ¨¡å‹åç§°"))
        self.gpt_model = QLineEdit()
        self.gpt_model.setPlaceholderText("ä¾‹å¦‚ï¼šdeepseek-chat")
        self.advanced_settings_layout.addWidget(self.gpt_model)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸš€ è‡ªå®šä¹‰APIåœ°å€ï¼ˆgpt-customï¼‰"))
        self.gpt_address = QLineEdit()
        self.gpt_address.setPlaceholderText("ä¾‹å¦‚ï¼šhttp://127.0.0.1:11434")
        self.advanced_settings_layout.addWidget(self.gpt_address)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ’» ç¦»çº¿æ¨¡å‹æ–‡ä»¶ï¼ˆgaltranslï¼Œ sakuraï¼Œllamacppï¼‰"))
        self.sakura_file = QComboBox()
        sakura_lst = [i for i in os.listdir('llama') if i.endswith('gguf')]
        self.sakura_file.addItems(sakura_lst)
        self.advanced_settings_layout.addWidget(self.sakura_file)
        
        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ’» ç¦»çº¿æ¨¡å‹å‚æ•°ï¼ˆgaltranslï¼Œ sakuraï¼Œllamacppï¼‰"))
        self.sakura_value = QLineEdit()
        self.sakura_value.setPlaceholderText("100")
        self.sakura_value.setReadOnly(True)
        self.advanced_settings_layout.addWidget(self.sakura_value)
        self.sakura_mode = QSlider(Qt.Orientation.Horizontal)
        self.sakura_mode.setRange(0, 100)
        self.sakura_mode.setValue(100)
        self.sakura_mode.valueChanged.connect(lambda: self.sakura_value.setText(str(self.sakura_mode.value())))
        self.advanced_settings_layout.addWidget(self.sakura_mode)

        self.open_model_dir = QPushButton("ğŸ“ æ‰“å¼€ç¦»çº¿æ¨¡å‹ç›®å½•")
        self.open_model_dir.clicked.connect(lambda: os.startfile(os.path.join(os.getcwd(),'llama')))
        self.advanced_settings_layout.addWidget(self.open_model_dir)

        self.advanced_settings_layout.addWidget(BodyLabel("ğŸ”§ è¾“å…¥Llama.cppå‘½ä»¤è¡Œå‚æ•°ã€‚"))
        self.param_llama = QTextEdit()
        self.param_llama.setPlaceholderText("æ¯ä¸ªå‚æ•°ç©ºæ ¼éš”å¼€ï¼Œè¯·å‚è€ƒLlama.cppæ–‡æ¡£ï¼Œä¸æ¸…æ¥šè¯·ä¿æŒé»˜è®¤ã€‚")
        self.advanced_settings_layout.addWidget(self.param_llama)

        self.addSubInterface(self.advanced_settings_tab, FluentIcon.BOOK_SHELF, "ç¿»è¯‘è®¾ç½®", NavigationItemPosition.TOP)






        
    def select_input(self):
        options = QFileDialog.Options()
        files, _ = QFileDialog.getOpenFileNames(self, "é€‰æ‹©éŸ³è§†é¢‘æ–‡ä»¶/SRTæ–‡ä»¶", "", "All Files (*);;Video Files (*.mp4 *.webm, *.flv);;SRT Files (*.srt);;Audio Files (*.wav, *.mp3, *.flac)", options=options)
        if files:
            self.input_files_list.setPlainText('\n'.join(files))

    def run_worker(self):
        self.thread = QThread()
        self.worker = MainWorker(self)
        self.worker.moveToThread(self.thread)
        self.thread.started.connect(self.worker.run)
        self.worker.finished.connect(self.thread.quit)
        self.thread.start()




    
    def cleaner(self):
        self.status.emit("[INFO] æ­£åœ¨æ¸…ç†ä¸­é—´æ–‡ä»¶...")
        if os.path.exists('project/gt_input'):
            shutil.rmtree('project/gt_input')
        if os.path.exists('project/gt_output'):
            shutil.rmtree('project/gt_output')
        if os.path.exists('project/transl_cache'):
            shutil.rmtree('project/transl_cache')
        self.status.emit("[INFO] æ­£åœ¨æ¸…ç†è¾“å‡º...")
        if os.path.exists('project/cache'):
            shutil.rmtree('project/cache')
        os.makedirs('project/cache', exist_ok=True)

def error_handler(func):
    def wrapper(self):
        try:
            func(self)
        except Exception as e:
            self.status.emit(f"[ERROR] {e}")
            self.finished.emit()
    return wrapper
class MainWorker(QObject):
    finished = pyqtSignal()

    def __init__(self, master):
        super().__init__()
        self.master = master
        self.status = master.status

    @error_handler
    def save_config(self):
        self.status.emit("[INFO] æ­£åœ¨è¯»å–é…ç½®...")
        # No whisper_file needed - always use anime-whisper
        translator = self.master.translator_group.currentText()
        language = self.master.input_lang.currentText()
        gpt_token = self.master.gpt_token.text()
        gpt_address = self.master.gpt_address.text()
        gpt_model = self.master.gpt_model.text()
        sakura_file = self.master.sakura_file.currentText()
        sakura_mode = self.master.sakura_mode.value()
        output_format = self.master.output_format.currentText()

        # save config (keep format for compatibility, but whisper_file is always anime-whisper)
        with open('config.txt', 'w', encoding='utf-8') as f:
            f.write(f"anime-whisper\n{translator}\n{language}\n{gpt_token}\n{gpt_address}\n{gpt_model}\n{sakura_file}\n{sakura_mode}\n{output_format}\n")

        # save anime-whisper config
        with open('anime_whisper_config.txt', 'w', encoding='utf-8') as f:
            if self.master.suppress_repetitions.currentText() == 'å¯ç”¨é‡å¤æŠ‘åˆ¶':
                f.write('suppress_repetitions')
            else:
                f.write('')

        # save llama param
        with open('llama/param.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.param_llama.toPlainText())

        # save before dict
        with open('project/dict_pre.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.before_dict.toPlainText())

        # save gpt dict
        with open('project/dict_gpt.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.gpt_dict.toPlainText())

        # save after dict
        with open('project/dict_after.txt', 'w', encoding='utf-8') as f:
            f.write(self.master.after_dict.toPlainText())

        self.status.emit("[INFO] é…ç½®ä¿å­˜å®Œæˆï¼")















    @error_handler
    def run(self):
        self.save_config()
        input_files = self.master.input_files_list.toPlainText()
        # Use hybrid transcription system for better accuracy
        translator = self.master.translator_group.currentText()
        language = self.master.input_lang.currentText()
        gpt_token = self.master.gpt_token.text()
        gpt_address = self.master.gpt_address.text()
        gpt_model = self.master.gpt_model.text()
        sakura_file = self.master.sakura_file.currentText()
        sakura_mode = self.master.sakura_mode.value()
        before_dict = self.master.before_dict.toPlainText()
        gpt_dict = self.master.gpt_dict.toPlainText()
        after_dict = self.master.after_dict.toPlainText()
        extra_prompt = self.master.extra_prompt.toPlainText()
        # Get anime-whisper config
        suppress_repetitions = self.master.suppress_repetitions.currentText() == 'å¯ç”¨é‡å¤æŠ‘åˆ¶'
        param_llama = self.master.param_llama.toPlainText()
        output_format = self.master.output_format.currentText()

        if not gpt_token:
            gpt_token = 'sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'

        # Old whisper parameter files are no longer needed

        with open('llama/param.txt', 'w', encoding='utf-8') as f:
            f.write(param_llama)

        self.status.emit("[INFO] æ­£åœ¨åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹...")

        os.makedirs('project/cache', exist_ok=True)
        if before_dict:
            with open('project/dict_pre.txt', 'w', encoding='utf-8') as f:
                f.write(before_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_pre.txt'):
                os.remove('project/dict_pre.txt')
        if gpt_dict:
            with open('project/dict_gpt.txt', 'w', encoding='utf-8') as f:
                f.write(gpt_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_gpt.txt'):
                os.remove('project/dict_gpt.txt')
        if after_dict:
            with open('project/dict_after.txt', 'w', encoding='utf-8') as f:
                f.write(after_dict.replace(' ','\t'))
        else:
            if os.path.exists('project/dict_after.txt'):
                os.remove('project/dict_after.txt')
        if extra_prompt:
            with open('project/extra_prompt.txt', 'w', encoding='utf-8') as f:
                f.write(extra_prompt)
        else:
            if os.path.exists('project/extra_prompt.txt'):
                os.remove('project/extra_prompt.txt')

        self.status.emit(f"[INFO] å½“å‰è¾“å…¥æ–‡ä»¶ï¼š{input_files}")

        if input_files:
            input_files = input_files.split('\n')
        else:
            input_files = []

        os.makedirs('project/cache', exist_ok=True)

        self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œç¿»è¯‘é…ç½®...")
        with open('project/config.yaml', 'r', encoding='utf-8') as f:
            lines = f.readlines()

        for idx, line in enumerate(lines):
            if 'language' in line:
                lines[idx] = f'  language: "{language}2zh-cn"\n'
            if 'gpt' in translator:
                if not gpt_address:
                    gpt_address = 'https://api.openai.com'
                if not gpt_model:
                    gpt_model = ''
                if 'GPT35:' in line:
                    lines[idx+2] = f"      - token: {gpt_token}\n"
                    lines[idx+4] = f"    defaultEndpoint: {gpt_address}\n"
                    lines[idx+5] = f'    rewriteModelName: "{gpt_model}"\n'
            for name, api in ONLINE_TRANSLATOR_MAPPING.items():
                if name == translator:
                    if 'llamacpp' in translator:
                        gpt_model = sakura_file
                    if 'GPT35:' in line:
                        lines[idx+2] = f"      - token: {gpt_token}\n"
                        lines[idx+4] = f"    defaultEndpoint: {api}\n"
                        lines[idx+5] = f'    rewriteModelName: "{gpt_model}"\n'
            if 'proxy' in line:
                lines[idx+1] = "  enableProxy: false\n"

        with open('project/config.yaml', 'w', encoding='utf-8') as f:
            f.writelines(lines)

        for idx, input_file in enumerate(input_files):
            if not os.path.exists(input_file):
                self.status.emit(f"[ERROR] æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_file}")
                continue

            self.status.emit(f"[INFO] å½“å‰å¤„ç†æ–‡ä»¶ï¼š{input_file} ç¬¬{idx+1}ä¸ªï¼Œå…±{len(input_files)}ä¸ª")

            os.makedirs('project/gt_input', exist_ok=True)
            if input_file.endswith('.srt'):
                self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œå­—å¹•è½¬æ¢...")
                output_file_path = os.path.join('project/gt_input', os.path.basename(input_file).replace('.srt','.json'))
                make_prompt(input_file, output_file_path)
                self.status.emit("[INFO] å­—å¹•è½¬æ¢å®Œæˆï¼")
                input_file = input_file[:-4]
            else:
                # Perform transcription with hybrid system for improved timestamp accuracy

                # Check if input audio file exists
                if not os.path.exists(input_file):
                    self.status.emit("[ERROR] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼")
                    break

                self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")

                # Use hybrid transcription system for better timestamp accuracy
                try:
                    from hybrid_transcription_backend import HybridTranscriptionBackend

                    # Get alignment backend configuration
                    backend_text = self.master.alignment_backend.currentText()
                    if backend_text == 'OpenAIå…¼å®¹API':
                        alignment_type = "openai"
                    elif backend_text == 'GeminiåŸç”ŸAPI':
                        alignment_type = "gemini"
                    else:
                        alignment_type = "qwen3"

                    # Prepare configuration
                    config = {"alignment_type": alignment_type}

                    if alignment_type in ["openai", "gemini"]:
                        # Get API key (common for both)
                        api_key = self.master.api_key.text().strip()

                        if alignment_type == "openai":
                            config.update({
                                "api_endpoint": self.master.api_endpoint.text().strip(),
                                "api_key": api_key,
                                "model_name": self.master.api_model_input.text().strip()
                            })
                        else:  # gemini
                            config.update({
                                "api_key": api_key,
                                "model_name": self.master.gemini_model_combo.currentText()
                            })

                        # Validate API configuration
                        if not api_key:
                            self.status.emit("[ERROR] APIå¯†é’¥æœªé…ç½®")
                            continue

                        if alignment_type == "openai":
                            if not config["api_endpoint"]:
                                self.status.emit("[ERROR] APIç«¯ç‚¹æœªé…ç½®")
                                continue
                            if not config["model_name"]:
                                self.status.emit("[ERROR] æ¨¡å‹åç§°æœªé…ç½®")
                                continue
                        else:  # gemini
                            if not config["model_name"]:
                                self.status.emit("[ERROR] Geminiæ¨¡å‹æœªé€‰æ‹©")
                                continue

                    # Initialize hybrid transcription backend
                    alignment_name = {
                        "openai": "OpenAIå…¼å®¹API",
                        "gemini": "GeminiåŸç”ŸAPI",
                        "qwen3": "Qwen3"
                    }.get(alignment_type, "Qwen3")
                    self.status.emit(f"[INFO] åˆå§‹åŒ–æ··åˆè½¬å½•ç³»ç»Ÿ (TinyWhisper + AnimeWhisper + {alignment_name})...")
                    backend = HybridTranscriptionBackend(config)
                    if not backend.initialize():
                        self.status.emit("[ERROR] Failed to initialize hybrid transcription system")
                        continue

                    # Get configuration
                    suppress_repetitions = self.master.suppress_repetitions.currentText() == 'å¯ç”¨é‡å¤æŠ‘åˆ¶'

                    # Transcribe audio using hybrid system
                    self.status.emit("[INFO] ä½¿ç”¨æ··åˆè½¬å½•ç³»ç»Ÿè¿›è¡Œé«˜è´¨é‡è½¬å½•...")

                    srt_output_path = '.'.join(input_file.split('.')[:-1]) + '.srt'

                    # Define progress callback to update UI in real-time
                    def progress_callback(message):
                        self.status.emit(message)

                    success = backend.transcribe_to_srt(
                        input_file,  # Use original audio file directly
                        srt_output_path,
                        language=language,
                        progress_callback=progress_callback,
                        suppress_repetitions=suppress_repetitions
                    )

                    if not success:
                        self.status.emit("[ERROR] Hybrid transcription failed")
                        continue

                    self.status.emit("[INFO] âœ… æ··åˆè½¬å½•å®Œæˆï¼æ—¶é—´æˆ³å‡†ç¡®æ€§å¤§å¹…æå‡ï¼")

                    # Clean up backend
                    backend.cleanup()

                except Exception as e:
                    self.status.emit(f"[ERROR] Hybrid transcription error: {str(e)}")
                    # Fallback to original anime-whisper if hybrid system fails
                    self.status.emit("[INFO] å›é€€åˆ°åŸå§‹ AnimeWhisper ç³»ç»Ÿ...")
                    try:
                        from anime_whisper_backend import AnimeWhisperBackend

                        backend = AnimeWhisperBackend()
                        if not backend.initialize():
                            self.status.emit("[ERROR] Failed to initialize fallback anime-whisper model")
                            continue

                        suppress_repetitions = self.master.suppress_repetitions.currentText() == 'å¯ç”¨é‡å¤æŠ‘åˆ¶'
                        srt_output_path = '.'.join(input_file.split('.')[:-1]) + '.srt'

                        success = backend.transcribe_to_srt(
                            input_file,
                            srt_output_path,
                            language=language,
                            suppress_repetitions=suppress_repetitions
                        )

                        if not success:
                            self.status.emit("[ERROR] Fallback transcription also failed")
                            continue

                        backend.cleanup()
                        self.status.emit("[INFO] âš ï¸ ä½¿ç”¨å›é€€ç³»ç»Ÿå®Œæˆè½¬å½•")

                    except Exception as fallback_e:
                        self.status.emit(f"[ERROR] Fallback error: {str(fallback_e)}")
                        continue

                # Generate base filename without extension for further processing
                base_filename = '.'.join(input_file.split('.')[:-1])
                srt_file = base_filename + '.srt'

                output_file_path = os.path.join('project/gt_input', os.path.basename(base_filename)+'.json')
                make_prompt(srt_file, output_file_path)

                # For åŸæ–‡SRT, keep the SRT file generated by hybrid system
                # For other formats, clean up the temporary SRT file
                if output_format != 'åŸæ–‡SRT':
                    if os.path.exists(srt_file):
                        os.remove(srt_file)
                else:
                    self.status.emit(f"[INFO] åŸæ–‡SRTæ–‡ä»¶å·²ä¿å­˜: {srt_file}")
                self.status.emit("[INFO] è¯­éŸ³è¯†åˆ«å®Œæˆï¼")

            if translator == 'ä¸è¿›è¡Œç¿»è¯‘':
                self.status.emit("[INFO] ç¿»è¯‘å™¨æœªé€‰æ‹©ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                continue

            if language == 'zh':
                self.status.emit("[INFO] å¬å†™è¯­è¨€ä¸ºä¸­æ–‡ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                continue

            if 'sakura' in translator or 'llamacpp' in translator or 'galtransl' in translator:
                self.status.emit("[INFO] æ­£åœ¨å¯åŠ¨Llamacppç¿»è¯‘å™¨...")
                if not sakura_file:
                    self.status.emit("[INFO] æœªé€‰æ‹©æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡ç¿»è¯‘æ­¥éª¤...")
                    continue
                
                print(param_llama)
                self.pid = subprocess.Popen([param.replace('$model_file',sakura_file).replace('$num_layers',str(sakura_mode)).replace('$port', '8989') for param in param_llama.split()], stdout=sys.stdout, stderr=sys.stdout, creationflags=0x08000000)
                
                self.status.emit("[INFO] æ­£åœ¨ç­‰å¾…Sakuraç¿»è¯‘å™¨å¯åŠ¨...")
                while True:
                    try:
                        response = requests.get("http://localhost:8989")
                        if response.status_code == 200:
                            break
                    except requests.exceptions.RequestException:
                        pass
                    sleep(1)

            if 'galtransl' in translator:
                worker_trans = 'sakura-010'
            elif 'sakura' not in translator:
                worker_trans = 'gpt35-1106'
            else:
                worker_trans = translator

            self.status.emit("[INFO] æ­£åœ¨è¿›è¡Œç¿»è¯‘...")
            worker('project', 'config.yaml', worker_trans, show_banner=False)

            self.status.emit("[INFO] æ­£åœ¨ç”Ÿæˆå­—å¹•æ–‡ä»¶...")
            if output_format == 'ä¸­æ–‡SRT':
                make_srt(output_file_path.replace('gt_input','gt_output'), input_file+'.zh.srt')

            if output_format == 'ä¸­æ–‡LRC':
                make_lrc(output_file_path.replace('gt_input','gt_output'), input_file+'.lrc')

            self.status.emit("[INFO] å­—å¹•æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")

            if 'sakura' in translator or 'llamacpp' in translator or 'galtransl' in translator:
                self.status.emit("[INFO] æ­£åœ¨å…³é—­Llamacppç¿»è¯‘å™¨...")
                self.pid.kill()
                self.pid.terminate()

        self.status.emit("[INFO] æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
        self.finished.emit()

if __name__ == "__main__":
    app = QApplication(sys.argv)
    main_window = MainWindow()
    main_window.show()
    sys.exit(app.exec())
